<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LEARNING WITH SCKINTA</title>
    <link>/</link>
    <description>Recent content on LEARNING WITH SCKINTA</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 22 Aug 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Taking options from command line</title>
      <link>/post/2020-8-22_options/</link>
      <pubDate>Sat, 22 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020-8-22_options/</guid>
      <description>Taking in options from command line is an essential step towards generalized usage of scripts. However, it is a chapter I skipped in almost all language textbooks since my primary goal was to code for a specific problem and did not mind re-writing the scripts in different situations.
Usually the options following the scripts have two types
 direct inputs (with default definition within the script). the “true”&amp;quot; options with “-” or “–” to allow optional manipulation  For the second type of options, it becomes a little bit complicated.</description>
    </item>
    
    <item>
      <title>Transition from dplyr to data.table</title>
      <link>/post/2020-06-25_data_table/</link>
      <pubDate>Thu, 25 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020-06-25_data_table/</guid>
      <description>dplyr and tidyr have totally changed the way we code in R. I particularly love the pipe %&amp;gt;% which comes from magrittr package and makes the code easy to read and understand. While I am obessed with simplicity of dplyr coding style, I am also fascinated with how fast data.table wrangles data. Below is an example showing the speed difference using dplyr and data.table in a user function gene_lookup for one of my shiny app.</description>
    </item>
    
    <item>
      <title>ML pipeline with tidymodels vs. caret</title>
      <link>/post/2020-04-30_caret_vs_tidymodels/</link>
      <pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020-04-30_caret_vs_tidymodels/</guid>
      <description>As a DS beginner, I first came across ML in R by studying the book Hands-On Machine Learning with R. The book mainly focuses on the package caret with general introductions to packages like recipe and h2o. Most examples use the workflow in which feature engineering is performed by recipe and the modeling/learning part is done using caret.
It was a great pleasure to take the tidymodels workshop hosted by Dr.</description>
    </item>
    
    <item>
      <title>External persistent data I/O using ShinyApp</title>
      <link>/post/2020-03-30_shinyapp_tips/</link>
      <pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020-03-30_shinyapp_tips/</guid>
      <description>Shiny App is a fantastic application in Rstudio and makes the data processing more accessible (and fun!). Most easy shiny apps are made to represent data based on a given user input which is read into memory or temperal file by R and spit out tables or figures in the same process. However, to make an app that need to keep the user input data for persistent storage and present in the future process require some external data I/O.</description>
    </item>
    
    <item>
      <title>All about git</title>
      <link>/post/2020-02-11_all_about_git/</link>
      <pubDate>Tue, 11 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020-02-11_all_about_git/</guid>
      <description>Recently I have actively participated two team projects (PAWS and 2020datahack) which involves multiple team members and a lot of group decisions. For the first time, I realized how important to use github as the platform for code sharing and communication. Here I am going to share several commands that I frequently used at this process and hope it will help people quickly pick up this useful collaboration tool.</description>
    </item>
    
    <item>
      <title>PAWS return project EDA</title>
      <link>/post/2020-1-29-paws-return-eda/</link>
      <pubDate>Wed, 29 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/2020-1-29-paws-return-eda/</guid>
      <description>As my new year resolution, I decide to participate in more projects and horn programming skills by doing the work. One opportunity poped up at beginning this year. I am thrilled to participate and lead Rladies Philly’s new collaboration with Philadelphia Animal Welfare Society (PAWS) to analyze their animal data, aiming to help PAWS improving adoption process and clinic efficiency. This blog is part of explortory data analysis (EDA) I have done so far.</description>
    </item>
    
    <item>
      <title>From R to Python: Data Wrangling (part1)</title>
      <link>/post/2019-10-22_data_wrangling/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-10-22_data_wrangling/</guid>
      <description>Data wrangling usually stands as the first step for any data scientist. I started to learn data science by reading the book “R for Data Science”. The book is mainly an intro to the tidyverse, which is a collection of R packages designed for data science. It has its own grammar/syntax that can help users efficiently deal with data wrangling, visualization, string/date management, etc. As a regular tidyverse user now, I benefit a lot from the transition from base R to higher level R language in sophisticated packages.</description>
    </item>
    
    <item>
      <title>Network visualization (part3)</title>
      <link>/post/network_analysis_part3/</link>
      <pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/network_analysis_part3/</guid>
      <description>In the previous two posts (part1, part2), we discussed about IGRAPH object and how to manipulate, measure and cluster it. In this part3 of network analysis series, I will focus on the network work visualization.
Network visualization are supported by two aspects — the aestheic part of network elements (aka, vertices and edges) and layout of network. There are multiple packages available for these aspects. I will focus on the basic igraph plot (more like base R plot) and the application of ggraph (comparable to ggplot2)</description>
    </item>
    
    <item>
      <title>Network analysis part2</title>
      <link>/post/network_analysis_part2-2/</link>
      <pubDate>Sat, 24 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/network_analysis_part2-2/</guid>
      <description>In last post, we cover the basic components of IGRAPH objects and how to manipulate IGRAPH. You may notice that most of those manipulation do not really require a IGRAPH object to play with. However, in this post, you will realize the advantage of using IGRAPH in network analysis and how operation on IGRAPH object is much easier than using data.frame when doing network analysis.
In this session, we are going to use a new undirected graph (gr) generated by sample_gnp().</description>
    </item>
    
    <item>
      <title>Hi I&#39;m Sckinta</title>
      <link>/about/</link>
      <pubDate>Sun, 04 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>I am Chun (Sckinta) and I am currently a bioinformatics scientist at the Children’s Hospital of Philadelphia. Originally from China, I moved to the U.S. in 2011 and completed my PhD in Biology at the University of Virginia in 2017. Starting as a Perl programmer, I picked up R and Python on my own by taking online courses and local meetup workshops. I enjoy learning new programming skills and believe learning is a life-time mission and practice makes perfect.</description>
    </item>
    
    <item>
      <title>Network Analysis in R (part1)</title>
      <link>/post/network_analysis/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/network_analysis/</guid>
      <description>Network analysis is to study the complexity of the inter-relationships between actors of all sorts and provides an architectural view of individual actor connections. It has been applied to many fields, like social network and gene network, and useful for any systematic studies on individual relationship. wiki
This post plus following two posts (part2, part3) aim to introduce the termilogy that are frequently used in network and public available R tools that are useful for network analysis and visualization.</description>
    </item>
    
  </channel>
</rss>