---
title: 'Predict ultra race time using linear model and random forest'
author: "Sckinta"
date: "2021-11-02"
categories: ["r"]
tags: ["tidyTuesday", 'tidymodels']
output: 
  blogdown::html_page:
          toc: true
params:
  data_date: '2021-10-26'
---

<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#data-skim">data skim</a></li>
<li><a href="#eda">EDA</a><ul>
<li><a href="#the-effect-of-gender-and-age">the effect of gender and age</a></li>
<li><a href="#the-effect-of-nationality-age-gender">the effect of nationality, age, gender</a></li>
<li><a href="#effect-of-distance">effect of distance</a></li>
<li><a href="#effect-of-elevation">effect of elevation</a></li>
<li><a href="#effect-of-date">effect of date</a></li>
</ul></li>
<li><a href="#learning-models">learning models</a><ul>
<li><a href="#data-budget">data budget</a></li>
<li><a href="#recipes-for-feature-engineer">recipes for feature engineer</a></li>
<li><a href="#fit-linear-model">fit linear model</a></li>
<li><a href="#fit-random-forest-model-using-workflow">fit random forest model using workflow</a></li>
<li><a href="#last_fit-test-data-using-random-forest-result"><code>last_fit</code> test data using random forest result</a></li>
</ul></li>
<li><a href="#what-techniques-i-learned">what techniques i learned</a></li>
</ul>
</div>

<p>Load required libraries</p>
<pre class="r"><code>library(tidyverse)
library(tidymodels)
library(lubridate)</code></pre>
<div id="data-skim" class="section level2">
<h2>data skim</h2>
<p>Data README is available at <a href="https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-10-26/readme.md">here</a>.</p>
<pre class="r"><code>ultra_rankings &lt;- tuesdata$ultra_rankings
race &lt;- tuesdata$race

ultra_join &lt;-
    ultra_rankings %&gt;% 
    left_join(race, by=&quot;race_year_id&quot;)</code></pre>
<pre class="r"><code>skimr::skim(ultra_join)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-2">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">ultra_join</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">137803</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">20</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">9</td>
</tr>
<tr class="odd">
<td align="left">Date</td>
<td align="left">1</td>
</tr>
<tr class="even">
<td align="left">difftime</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">9</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">runner</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">3</td>
<td align="right">52</td>
<td align="right">0</td>
<td align="right">73629</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">time</td>
<td align="right">17791</td>
<td align="right">0.87</td>
<td align="right">8</td>
<td align="right">11</td>
<td align="right">0</td>
<td align="right">72840</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">gender</td>
<td align="right">30</td>
<td align="right">1.00</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">nationality</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">3</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">133</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">event</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">4</td>
<td align="right">57</td>
<td align="right">0</td>
<td align="right">435</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">race</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">3</td>
<td align="right">63</td>
<td align="right">0</td>
<td align="right">371</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">city</td>
<td align="right">15599</td>
<td align="right">0.89</td>
<td align="right">2</td>
<td align="right">30</td>
<td align="right">0</td>
<td align="right">308</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">country</td>
<td align="right">77</td>
<td align="right">1.00</td>
<td align="right">4</td>
<td align="right">17</td>
<td align="right">0</td>
<td align="right">60</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">participation</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: Date</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">min</th>
<th align="left">max</th>
<th align="left">median</th>
<th align="right">n_unique</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">date</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">2012-01-14</td>
<td align="left">2021-09-03</td>
<td align="left">2017-10-13</td>
<td align="right">711</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: difftime</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">min</th>
<th align="left">max</th>
<th align="left">median</th>
<th align="right">n_unique</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">start_time</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">0 secs</td>
<td align="left">82800 secs</td>
<td align="left">05:00:00</td>
<td align="right">39</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<colgroup>
<col width="15%" />
<col width="9%" />
<col width="13%" />
<col width="9%" />
<col width="8%" />
<col width="6%" />
<col width="7%" />
<col width="8%" />
<col width="6%" />
<col width="8%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">race_year_id</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">26678.70</td>
<td align="right">20156.18</td>
<td align="right">2320</td>
<td align="right">8670.0</td>
<td align="right">21795.0</td>
<td align="right">40621</td>
<td align="right">72496.0</td>
<td align="left">▇▃▃▂▂</td>
</tr>
<tr class="even">
<td align="left">rank</td>
<td align="right">17791</td>
<td align="right">0.87</td>
<td align="right">253.56</td>
<td align="right">390.80</td>
<td align="right">1</td>
<td align="right">31.0</td>
<td align="right">87.0</td>
<td align="right">235</td>
<td align="right">1962.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">age</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">46.25</td>
<td align="right">10.11</td>
<td align="right">0</td>
<td align="right">40.0</td>
<td align="right">46.0</td>
<td align="right">53</td>
<td align="right">133.0</td>
<td align="left">▁▇▂▁▁</td>
</tr>
<tr class="even">
<td align="left">time_in_seconds</td>
<td align="right">17791</td>
<td align="right">0.87</td>
<td align="right">122358.26</td>
<td align="right">37234.38</td>
<td align="right">3600</td>
<td align="right">96566.0</td>
<td align="right">114167.0</td>
<td align="right">148020</td>
<td align="right">296806.0</td>
<td align="left">▁▇▆▁▁</td>
</tr>
<tr class="odd">
<td align="left">distance</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">154.08</td>
<td align="right">39.22</td>
<td align="right">0</td>
<td align="right">160.9</td>
<td align="right">162.6</td>
<td align="right">168</td>
<td align="right">179.1</td>
<td align="left">▁▁▁▁▇</td>
</tr>
<tr class="even">
<td align="left">elevation_gain</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">6473.94</td>
<td align="right">3293.50</td>
<td align="right">0</td>
<td align="right">3910.0</td>
<td align="right">6640.0</td>
<td align="right">9618</td>
<td align="right">14430.0</td>
<td align="left">▅▆▆▇▁</td>
</tr>
<tr class="odd">
<td align="left">elevation_loss</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">-6512.20</td>
<td align="right">3305.73</td>
<td align="right">-14440</td>
<td align="right">-9618.0</td>
<td align="right">-6810.0</td>
<td align="right">-3950</td>
<td align="right">0.0</td>
<td align="left">▁▇▆▅▅</td>
</tr>
<tr class="even">
<td align="left">aid_stations</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">9.58</td>
<td align="right">7.56</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">12.0</td>
<td align="right">16</td>
<td align="right">56.0</td>
<td align="left">▇▇▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">participants</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">510.75</td>
<td align="right">881.25</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">65.0</td>
<td align="right">400</td>
<td align="right">2900.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
</tbody>
</table>
</div>
<div id="eda" class="section level2">
<h2>EDA</h2>
<p>We want to estimate the time (time_in_seconds) for runner to finish based on the features.</p>
<div id="the-effect-of-gender-and-age" class="section level3">
<h3>the effect of gender and age</h3>
<pre class="r"><code>ultra_join %&gt;% 
    filter(!is.na(time_in_seconds)) %&gt;% 
    filter(!is.na(gender)) %&gt;% 
    filter(age &gt; 10, age &lt; 100) %&gt;% 
    mutate(age_decade = 5* (age %/% 5)) %&gt;% 
    select(time_in_seconds, gender, age, age_decade) %&gt;% 
    group_by(age_decade, gender) %&gt;% 
    summarise(
        time_in_seconds_sd = sd(time_in_seconds),
         time_in_seconds = mean(time_in_seconds)
    ) %&gt;% 
    ggplot(aes(x = age_decade, color=gender, group=gender)) +
    geom_point(aes(y=time_in_seconds)) +
    geom_line(aes(y=time_in_seconds)) +
    geom_errorbar(aes(ymin=time_in_seconds - time_in_seconds_sd, ymax=time_in_seconds + time_in_seconds_sd), width=0.2, alpha=0.7) +
    scale_color_viridis_d() +
    labs(x = &quot;age&quot;, y = &quot;time (second)&quot;) +
    scale_y_continuous(labels = scales::label_comma())</code></pre>
<p><img src="/post/2021-11-02_tidyTues_ultraRace_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="the-effect-of-nationality-age-gender" class="section level3">
<h3>the effect of nationality, age, gender</h3>
<pre class="r"><code>ultra_join %&gt;% 
    mutate(nationality = fct_lump(nationality, prop=0.05)) %&gt;% 
    count(nationality, sort=TRUE) </code></pre>
<pre><code>## # A tibble: 4 × 2
##   nationality     n
##   &lt;fct&gt;       &lt;int&gt;
## 1 Other       50563
## 2 USA         47259
## 3 FRA         28905
## 4 GBR         11076</code></pre>
<pre class="r"><code>ultra_join %&gt;% 
    filter(!is.na(time_in_seconds)) %&gt;% 
    filter(!is.na(gender)) %&gt;% 
    filter(age &gt; 10, age &lt; 100) %&gt;% 
    mutate(nationality = fct_lump(nationality, prop=0.05)) %&gt;% 
    ggplot(aes(x = age, fill=nationality), group=nationality) +
    facet_wrap(vars(gender)) +
    geom_bar(stat=&quot;density&quot;, alpha=0.5)</code></pre>
<p><img src="/post/2021-11-02_tidyTues_ultraRace_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>nationality</p>
<pre class="r"><code>ultra_join %&gt;% 
    filter(!is.na(time_in_seconds)) %&gt;% 
    filter(!is.na(gender)) %&gt;% 
    filter(age &gt; 10, age &lt; 100) %&gt;% 
    mutate(nationality = fct_lump(nationality, prop=0.05)) %&gt;% 
    ggplot(aes(x=fct_reorder(nationality, time_in_seconds), y=time_in_seconds, fill=nationality)) +
    geom_boxplot() +
    scale_fill_viridis_d() +
    labs(x=&quot;runner&#39;s nationality&quot;, fill=NULL, y=&quot;time (second)&quot;) +
    scale_y_continuous(labels = scales::label_comma())</code></pre>
<p><img src="/post/2021-11-02_tidyTues_ultraRace_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="effect-of-distance" class="section level3">
<h3>effect of distance</h3>
<pre class="r"><code>ultra_join %&gt;% 
    filter(!is.na(time_in_seconds)) %&gt;% 
    filter(distance &gt;= 150) %&gt;% 
    ggplot(aes(x=distance, y=time_in_seconds)) +
    geom_point(alpha=0.1, size=1) +
    geom_smooth() +
    labs(y=&quot;time (second)&quot;) +
    scale_y_continuous(labels = scales::label_comma())</code></pre>
<p><img src="/post/2021-11-02_tidyTues_ultraRace_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="effect-of-elevation" class="section level3">
<h3>effect of elevation</h3>
<pre class="r"><code>ultra_join %&gt;% 
    filter(!is.na(time_in_seconds)) %&gt;% 
    filter(distance &gt;= 150) %&gt;% 
    mutate(elevation = ifelse(
        elevation_gain &gt; abs(elevation_loss), elevation_gain,  abs(elevation_loss)
        )) %&gt;% 
    ggplot(aes(x=elevation , y=time_in_seconds)) +
    geom_point(alpha=0.1, size=1) +
    geom_smooth() +
    labs(y=&quot;time (second)&quot;) +
    scale_y_continuous(labels = scales::label_comma())</code></pre>
<p><img src="/post/2021-11-02_tidyTues_ultraRace_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="effect-of-date" class="section level3">
<h3>effect of date</h3>
<p>The year of the race</p>
<pre class="r"><code>ultra_join %&gt;% 
    filter(!is.na(time_in_seconds)) %&gt;% 
    mutate(
        race_year=lubridate::year(date), 
        race_month=lubridate::month(date)
    ) %&gt;% 
    group_by(race_year) %&gt;% 
    summarise(
        time_in_seconds_sd=mean(time_in_seconds),
        time_in_seconds=mean(time_in_seconds)
    ) %&gt;% 
    ungroup() %&gt;% 
    ggplot(aes(x=race_year, y=time_in_seconds)) +
    geom_point() +
    geom_line() +
    geom_errorbar(aes(ymin=time_in_seconds - time_in_seconds_sd, ymax=time_in_seconds + time_in_seconds_sd), alpha=0.5)</code></pre>
<p><img src="/post/2021-11-02_tidyTues_ultraRace_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>The month of race can be the proxy to estimate the season when race was hosted. However, here I did not take the geographic information (hemisphere) into consideration.</p>
<pre class="r"><code>ultra_join %&gt;% 
    filter(!is.na(time_in_seconds)) %&gt;% 
    mutate(
        race_year=lubridate::year(date), 
        race_month=lubridate::month(date)
    ) %&gt;% 
    group_by(race_month) %&gt;% 
    summarise(
        time_in_seconds_sd=mean(time_in_seconds),
        time_in_seconds=mean(time_in_seconds)
    ) %&gt;% 
    ungroup() %&gt;% 
    ggplot(aes(x=race_month, y=time_in_seconds)) +
    geom_point() +
    geom_line() +
    geom_errorbar(aes(ymin=time_in_seconds - time_in_seconds_sd, ymax=time_in_seconds + time_in_seconds_sd), alpha=0.5)</code></pre>
<p><img src="/post/2021-11-02_tidyTues_ultraRace_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
</div>
<div id="learning-models" class="section level2">
<h2>learning models</h2>
<p>Here I will perform two distinct models – linear regression and random forest to predict the race time using runner’s gender, age, nationality, elevation and distance of race.</p>
<div id="data-budget" class="section level3">
<h3>data budget</h3>
<p>inistal split to train and test</p>
<pre class="r"><code>ultra_df &lt;- ultra_join %&gt;% 
  filter(!is.na(time_in_seconds)) %&gt;% 
  filter(!is.na(gender)) %&gt;% 
  filter(age &gt; 10, age &lt; 100) %&gt;% 
  filter(distance &gt;= 150) %&gt;% 
  mutate(elevation = ifelse(
        elevation_gain &gt; abs(elevation_loss), 
        elevation_gain,
        abs(elevation_loss)
        )
  ) %&gt;% 
  select(time_in_seconds, age, gender, nationality, distance, elevation)

set.seed(2021)
ultra_split &lt;- initial_split(ultra_df, strata = time_in_seconds)
ultra_train &lt;- training(ultra_split)
ultra_test &lt;- testing(ultra_split)</code></pre>
<p>create resamples for cross validation</p>
<pre class="r"><code>set.seed(124)
ultra_folds &lt;- vfold_cv(ultra_train, v=10)</code></pre>
</div>
<div id="recipes-for-feature-engineer" class="section level3">
<h3>recipes for feature engineer</h3>
<pre class="r"><code>ultra_rec &lt;- recipe(time_in_seconds ~., data = ultra_train) %&gt;% 
  step_other(nationality) %&gt;% 
  step_normalize(all_numeric_predictors()) %&gt;% 
  step_string2factor(all_nominal_predictors()) %&gt;% 
  # step_dummy(all_nominal_predictors()) %&gt;% 
  I()

# want to test whether dummy variables affect the model behave
ind_rec &lt;- ultra_rec %&gt;% 
  step_dummy(all_nominal_predictors())</code></pre>
</div>
<div id="fit-linear-model" class="section level3">
<h3>fit linear model</h3>
<p>specify models</p>
<pre class="r"><code>lm_spec &lt;- linear_reg() %&gt;% 
  set_engine(&#39;lm&#39;) %&gt;% 
  set_mode(&#39;regression&#39;)</code></pre>
<p>Does linear model need dummy variable? Using <code>workflow_set</code> to test</p>
<pre class="r"><code>lm_wf &lt;- workflow_set(
  preproc = list(&quot;nodummy&quot;=ultra_rec, &quot;dummy&quot;=ind_rec),
  models = list(lm_spec)
)

lm_rs &lt;- workflow_map(
  lm_wf, &#39;fit_resamples&#39;, resamples=ultra_folds
  )

lm_rs %&gt;% collect_metrics()</code></pre>
<pre><code>## # A tibble: 4 × 9
##   wflow_id    .config    preproc model  .metric .estimator    mean     n std_err
##   &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 nodummy_li… Preproces… AsIs    linea… rmse    standard   2.39e+4    10 6.94e+1
## 2 nodummy_li… Preproces… AsIs    linea… rsq     standard   5.66e-1    10 2.73e-3
## 3 dummy_line… Preproces… AsIs    linea… rmse    standard   2.39e+4    10 6.94e+1
## 4 dummy_line… Preproces… AsIs    linea… rsq     standard   5.66e-1    10 2.73e-3</code></pre>
<p>Based on the r-square value, the linear model with age, distance, elevation, gender and nationality explained ~57% variance of time_in_seconds.</p>
<p>Using dummy variable or not does not change the metrics. In fact, the number of coefficients will be exactly same no matter whether using dummy or not. Below shows coefficients of linear regression by fitting the “nodummy_linear_reg” workflow to the training data.</p>
<pre class="r"><code>lm_coef &lt;- lm_rs %&gt;% 
  extract_workflow(&#39;nodummy_linear_reg&#39;) %&gt;% 
  fit(ultra_train) %&gt;% 
  tidy()

lm_coef</code></pre>
<pre><code>## # A tibble: 9 × 5
##   term             estimate std.error statistic   p.value
##   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)       142711.     217.      658.  0        
## 2 age                 4220.      83.3      50.6 0        
## 3 genderW             6315.     236.       26.8 1.82e-157
## 4 nationalityGBR    -25432.     389.      -65.3 0        
## 5 nationalityJPN    -20211.     406.      -49.8 0        
## 6 nationalityUSA    -30025.     302.      -99.6 0        
## 7 nationalityother  -19682.     254.      -77.6 0        
## 8 distance            2630.      99.2      26.5 2.65e-154
## 9 elevation          17421.     117.      149.  0</code></pre>
<pre class="r"><code>lm_coef %&gt;% 
  filter(term!=&quot;(Intercept)&quot;) %&gt;% 
  ggplot(aes(x = estimate, y = fct_reorder(term, estimate))) +
  geom_col(aes(fill=(estimate &lt; 0)), alpha = 0.5) +
  geom_errorbar(aes(xmin=estimate - std.error, xmax = estimate + std.error), width=0.5) +
  theme(legend.position = &#39;none&#39;) +
  labs(fill=NULL, y = NULL)</code></pre>
<p><img src="/post/2021-11-02_tidyTues_ultraRace_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Elevation, being a women (compare to being a men), age and distance positively affect race time, while racers from JPN/GBR/USA/other (compare to racers from FRA) finish the race in shorter time.</p>
</div>
<div id="fit-random-forest-model-using-workflow" class="section level3">
<h3>fit random forest model using workflow</h3>
<p>Using random forest as model to get Resampling results</p>
<pre class="r"><code>rf_spec &lt;- rand_forest() %&gt;% 
  set_engine(&#39;ranger&#39;) %&gt;% 
  set_mode(&#39;regression&#39;)

rf_wf &lt;- workflow() %&gt;% 
  add_model(rf_spec) %&gt;% 
  add_recipe(ultra_rec)

# resample evaluate 
rf_rs  &lt;- rf_wf %&gt;% 
  fit_resamples(
    resamples = ultra_folds
  )</code></pre>
<pre class="r"><code>rf_rs  %&gt;% 
  collect_metrics()</code></pre>
<pre><code>## # A tibble: 2 × 6
##   .metric .estimator      mean     n  std_err .config             
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard   18535.       10 57.2     Preprocessor1_Model1
## 2 rsq     standard       0.738    10  0.00219 Preprocessor1_Model1</code></pre>
<p>Compared to linear model shown above, random forest with same predictors can explain more variance of Y (74% vs. 56%) and show smaller rmse (1.8e4 vs. 2.4e4).</p>
<pre class="r"><code>bind_rows(
  rf_rs  %&gt;% 
    collect_metrics() %&gt;% 
    select(.metric, mean, std_err) %&gt;% 
    mutate(model = &quot;random forest&quot;),
  lm_rs  %&gt;% 
    collect_metrics() %&gt;% 
    filter(wflow_id == &#39;nodummy_linear_reg&#39;) %&gt;% 
    select(.metric, mean, std_err) %&gt;% 
    mutate(model = &quot;linear reg&quot;)
) %&gt;% 
  ggplot(aes(x = model, y = mean)) +
  facet_wrap(vars(.metric), scales = &#39;free&#39;) +
  geom_point() +
  geom_errorbar(aes(ymin=mean - std_err, ymax=mean + std_err), width=0)</code></pre>
<p><img src="/post/2021-11-02_tidyTues_ultraRace_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Notes: above plot can also be done by autoplot if we perform the comparison between linear regression and random forest models using <code>workflow_set</code>.</p>
</div>
<div id="last_fit-test-data-using-random-forest-result" class="section level3">
<h3><code>last_fit</code> test data using random forest result</h3>
<pre class="r"><code>rf_final_rs &lt;- rf_wf %&gt;% 
  last_fit(ultra_split)</code></pre>
<pre class="r"><code>rf_final_rs %&gt;% 
  collect_metrics()</code></pre>
<pre><code>## # A tibble: 2 × 4
##   .metric .estimator .estimate .config             
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard   18558.    Preprocessor1_Model1
## 2 rsq     standard       0.737 Preprocessor1_Model1</code></pre>
<p>Different from <code>fit_resample</code> results, these metrics are calculated on the test data. The value is very close to the values done on training data (resample data), thus the model is not over-fitted.</p>
<pre class="r"><code>final_wf &lt;- rf_final_rs %&gt;% 
  extract_workflow()

final_wf</code></pre>
<pre><code>## ══ Workflow [trained] ══════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: rand_forest()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 3 Recipe Steps
## 
## • step_other()
## • step_normalize()
## • step_string2factor()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## Ranger result
## 
## Call:
##  ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) 
## 
## Type:                             Regression 
## Number of trees:                  500 
## Sample size:                      83042 
## Number of independent variables:  5 
## Mtry:                             2 
## Target node size:                 5 
## Variable importance mode:         none 
## Splitrule:                        variance 
## OOB prediction error (MSE):       342756874 
## R squared (OOB):                  0.7386866</code></pre>
<p>The above <strong>trained</strong> workflow from <code>last_fit</code> can be saved in <code>.rda</code> for future prediction</p>
<pre class="r"><code># using final_wf for prediction
final_wf %&gt;% 
  predict(new_data = ultra_train %&gt;% dplyr::slice(1)) </code></pre>
<pre><code>## # A tibble: 1 × 1
##     .pred
##     &lt;dbl&gt;
## 1 108741.</code></pre>
</div>
</div>
<div id="what-techniques-i-learned" class="section level2">
<h2>what techniques i learned</h2>
<ul>
<li>deal with high-levels nominal features (<code>fct_lump</code> and <code>step_other</code>) in EDA and modeling</li>
<li><code>workflow_set</code> and <code>map_workflow</code> to create multiple workflows for model and/or recipes comparison.</li>
<li><code>fit_resample</code> for cross-validation. The metrics collected from cross-validation results are used for workflow comparison.</li>
<li><code>last_fit</code> model and save <strong>trained</strong> workflow for future use</li>
</ul>
</div>
